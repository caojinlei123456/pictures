# 数据挖掘的聚类算法

## 层次化聚类（树聚类算法）

**典型**：BIRCH算法，CURE算法，NN算法

![è¿éåå¾çæè¿°](D:\学习成长\markdown\数据挖掘的聚类算法.assets\20180301171047257.gif)

**定义**：首先将每个样本看成单个簇，然后采取自下而上或是自上而下的策略，按照接近度来组合，形成类似树形的聚类结构。

**优点**：

1. 根据距离或者相似度进行定义
2. 不需要预先制定聚类数
3. 可以发现类的层次关系

**缺点**

1. 计算复杂度较高
2. 奇异值也能产生很大影响
3. 算法聚类结果可能成链状

## 基于划分的聚类

**典型**：K-means

**定义**：挑选K个点，利用启发式算法对数据点做迭代，达到“类内的点都足够近，类间的点都足够远”的效果

**优点**：

1. 简单、易于理解
2. 时间复杂度低

**缺点**：

1. 对初始K很敏感，需要手工输入类数目。
2. 对噪声和离群值很敏感。
3. 主要用于球或圆形簇，不能识别非球形簇。

## 基于密度的聚类

**典型**：DBSCAN（Density-Based Spatial Clustering of Applications with Noise），OPTICS（OrderingPoints To Identify Clustering Structure）

**定义**：给定一个距离半径和类内最少多少个点，然后把可以满足的点全部都连起来，判定为同类。

**优点**：

1. 与K_means比，不需要知道K，且能发现任意非球形状的簇类。
2. 同时，DBSCAN能够识别出噪声点。
3. 对输入样本顺序不敏感

**缺点**：

1. 不适用于高纬度数据
2. 不能很好的反应数据集变化的密度
3. 时间复杂度较高

## 基于网格的聚类

**典型**：STRING（Statistical Information Grid）、CLIQUE、WaveCluster

**定义**：将数据空间进行网格化划分，使用网格单元内数据的统计信息对数据进行压缩表达，基于这些信息判断高密度网格单元，将高密度网格单元相连识别为簇。

**优点：**

1. 有效减少计算复杂度
2. 一般适用于较高纬数据，可获取任意形状

**缺点：**

1. 参数敏感
2. 仍不适用于超高纬数据
